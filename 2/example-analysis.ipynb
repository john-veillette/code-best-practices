{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a36e817",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import stdtr as t_cdf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b369470",
   "metadata": {},
   "source": [
    "If you have your function definitions in another file (here, we've called our `util.py`), and that file is sitting in your working directory, then you can import them as if there's an installed package with that filename. That's because Python treats both `.py` files and packages as _modules._ \n",
    "\n",
    "You can import all the functions in a module using `*` as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd9578e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac03e7b8",
   "metadata": {},
   "source": [
    "But that's not a great thing to do. Why? (1) You'll end up importing stuff you don't use, cluttering your namespace, and (2) it won't be obvious where the functions you use in you script came from. For instance, if you write\n",
    "`from util import *` and `from scipy import *`, and then you call `ttest_1samp`, nobody is going to know whether `ttest_1samp` comes from `util` or `scipy`. That would be sad, since nobody could find our neatly written function definitions and docstrings.\n",
    "\n",
    "So instead, we do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17647634",
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import ttest_1samp, ttest_paired"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce92484",
   "metadata": {},
   "source": [
    "__Wow, did we just import more than one function from the same file!?!? Toto, I've a feeling we're not in MATLAB anymore!__ (Cough, cough @Anna.)\n",
    "\n",
    "Another option is to `import util` and then call the functions like `util.ttest_1samp`, which will also work. That's fine too, but it makes your code below a bit more verbose. Also, I just like importing all the functions I'll use at the top, so it's clear _why_ I'm importing each package. That's just my personal preference though. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18c03748",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data into a dataframe \n",
    "df = load_iris(as_frame = True)['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1be4070b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t = 1.611015, p = 0.054646\n"
     ]
    }
   ],
   "source": [
    "# our one-sample t-test\n",
    "t, p = ttest_1samp(df['sepal width (cm)'], null_mean = 3, tail = 1)\n",
    "print('t = %f, p = %f'%(t, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09104cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t = 29.796754, p = 1.200807e-64\n"
     ]
    }
   ],
   "source": [
    "# our paired -sample t-test\n",
    "t, p = ttest_paired(df['petal length (cm)'], df['petal width (cm)'], tail = 0)\n",
    "print('t = %f, p = %e'%(t, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405f7cd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
